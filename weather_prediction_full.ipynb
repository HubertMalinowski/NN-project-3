{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from weather_prediction_full import WeatherPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorfy(x):\n",
    "    return torch.tensor(x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = WeatherPipeline().prepare_datasets(\n",
    "    test_size=0.15,\n",
    "    val_size=0.15,\n",
    "    random_state=0,\n",
    "    load_processed=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size_temp, output_size_wind):\n",
    "        super(WeatherModel, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        for in_size, out_size in itertools.pairwise([input_size] + list(hidden_sizes)):\n",
    "            layers.append(nn.Linear(in_size, out_size))\n",
    "            layers.append(nn.LeakyReLU())\n",
    "\n",
    "        self.fc1 = nn.Sequential(*layers)\n",
    "        self.fc2_temp = nn.Linear(hidden_sizes[-1], output_size_temp)  # Dla temperatury (regresja)\n",
    "        self.fc2_wind = nn.Linear(hidden_sizes[-1], output_size_wind)  # Dla wiatru (klasyfikacja)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = tensorfy(x)\n",
    "        out = self.fc1(x)\n",
    "        temp = self.fc2_temp(out)\n",
    "        wind = self.sigmoid(self.fc2_wind(out))\n",
    "        return temp.squeeze(), wind.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, tolerance=5, min_delta=0):\n",
    "        self.tolerance = tolerance\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, train_loss, validation_loss):\n",
    "        if (validation_loss - train_loss) > self.min_delta:\n",
    "            self.counter +=1\n",
    "            if self.counter >= self.tolerance:  \n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja funkcji trenowania modelu\n",
    "def train_model(model, train_data, val_data,\n",
    "               criterion_temp, criterion_wind, optimizer,\n",
    "               num_epochs=100):\n",
    "    X_train, y_temp_train, y_wind_train = train_data[\"X\"], tensorfy(train_data[\"y_temp\"]), tensorfy(train_data[\"y_wind\"])\n",
    "    X_val, y_temp_val, y_wind_val = val_data[\"X\"], tensorfy(val_data[\"y_temp\"]), tensorfy(val_data[\"y_wind\"])\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    early_stopper = EarlyStopping(tolerance=num_epochs//10, min_delta=0.01)\n",
    "    pbar = tqdm(range(num_epochs), desc='Training')\n",
    "    for epoch in pbar:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs_temp, outputs_wind = model(X_train)\n",
    "\n",
    "        loss_temp = criterion_temp(outputs_temp, y_temp_train)\n",
    "        loss_wind = criterion_wind(outputs_wind, y_wind_train)\n",
    "\n",
    "        loss = loss_temp + loss_wind\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Walidacja\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs_temp, val_outputs_wind = model(X_val)\n",
    "            val_loss_temp = criterion_temp(val_outputs_temp, y_temp_val)\n",
    "            val_loss_wind = criterion_wind(val_outputs_wind, y_wind_val)\n",
    "            val_loss = val_loss_temp + val_loss_wind\n",
    "\n",
    "        history['train_loss'].append(loss.item())\n",
    "        history['val_loss'].append(val_loss.item())\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
    "\n",
    "        early_stopper(loss, val_loss)\n",
    "        if early_stopper.early_stop:\n",
    "            break\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 50/5000 [00:00<00:19, 253.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/5000], Loss: 0.8822, Val Loss: 0.8469\n",
      "Epoch [20/5000], Loss: 0.7618, Val Loss: 0.7390\n",
      "Epoch [30/5000], Loss: 0.7118, Val Loss: 0.6924\n",
      "Epoch [40/5000], Loss: 0.6982, Val Loss: 0.6859\n",
      "Epoch [50/5000], Loss: 0.6904, Val Loss: 0.6802\n",
      "Epoch [60/5000], Loss: 0.6857, Val Loss: 0.6791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 105/5000 [00:00<00:18, 265.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/5000], Loss: 0.6829, Val Loss: 0.6776\n",
      "Epoch [80/5000], Loss: 0.6806, Val Loss: 0.6775\n",
      "Epoch [90/5000], Loss: 0.6786, Val Loss: 0.6779\n",
      "Epoch [100/5000], Loss: 0.6768, Val Loss: 0.6787\n",
      "Epoch [110/5000], Loss: 0.6751, Val Loss: 0.6795\n",
      "Epoch [120/5000], Loss: 0.6734, Val Loss: 0.6803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 162/5000 [00:00<00:17, 272.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [130/5000], Loss: 0.6717, Val Loss: 0.6810\n",
      "Epoch [140/5000], Loss: 0.6700, Val Loss: 0.6813\n",
      "Epoch [150/5000], Loss: 0.6683, Val Loss: 0.6814\n",
      "Epoch [160/5000], Loss: 0.6665, Val Loss: 0.6815\n",
      "Epoch [170/5000], Loss: 0.6647, Val Loss: 0.6813\n",
      "Epoch [180/5000], Loss: 0.6628, Val Loss: 0.6813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 222/5000 [00:00<00:18, 260.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [190/5000], Loss: 0.6609, Val Loss: 0.6813\n",
      "Epoch [200/5000], Loss: 0.6590, Val Loss: 0.6816\n",
      "Epoch [210/5000], Loss: 0.6573, Val Loss: 0.6818\n",
      "Epoch [220/5000], Loss: 0.6556, Val Loss: 0.6822\n",
      "Epoch [230/5000], Loss: 0.6539, Val Loss: 0.6830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 277/5000 [00:01<00:18, 254.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [240/5000], Loss: 0.6523, Val Loss: 0.6839\n",
      "Epoch [250/5000], Loss: 0.6508, Val Loss: 0.6845\n",
      "Epoch [260/5000], Loss: 0.6494, Val Loss: 0.6845\n",
      "Epoch [270/5000], Loss: 0.6481, Val Loss: 0.6847\n",
      "Epoch [280/5000], Loss: 0.6470, Val Loss: 0.6854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 330/5000 [00:01<00:18, 256.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [290/5000], Loss: 0.6460, Val Loss: 0.6864\n",
      "Epoch [300/5000], Loss: 0.6450, Val Loss: 0.6868\n",
      "Epoch [310/5000], Loss: 0.6439, Val Loss: 0.6876\n",
      "Epoch [320/5000], Loss: 0.6429, Val Loss: 0.6886\n",
      "Epoch [330/5000], Loss: 0.6419, Val Loss: 0.6891\n",
      "Epoch [340/5000], Loss: 0.6410, Val Loss: 0.6898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 382/5000 [00:01<00:18, 253.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [350/5000], Loss: 0.6402, Val Loss: 0.6906\n",
      "Epoch [360/5000], Loss: 0.6393, Val Loss: 0.6914\n",
      "Epoch [370/5000], Loss: 0.6381, Val Loss: 0.6913\n",
      "Epoch [380/5000], Loss: 0.6370, Val Loss: 0.6926\n",
      "Epoch [390/5000], Loss: 0.6358, Val Loss: 0.6927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 412/5000 [00:01<00:17, 264.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [400/5000], Loss: 0.6347, Val Loss: 0.6942\n",
      "Epoch [410/5000], Loss: 0.6338, Val Loss: 0.6941\n",
      "Epoch [420/5000], Loss: 0.6328, Val Loss: 0.6944\n",
      "Epoch [430/5000], Loss: 0.6317, Val Loss: 0.6935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 468/5000 [00:01<00:20, 216.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [440/5000], Loss: 0.6307, Val Loss: 0.6925\n",
      "Epoch [450/5000], Loss: 0.6298, Val Loss: 0.6928\n",
      "Epoch [460/5000], Loss: 0.6288, Val Loss: 0.6949\n",
      "Epoch [470/5000], Loss: 0.6278, Val Loss: 0.6970\n",
      "Epoch [480/5000], Loss: 0.6264, Val Loss: 0.6963\n",
      "Epoch [490/5000], Loss: 0.6253, Val Loss: 0.6950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 526/5000 [00:02<00:18, 244.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/5000], Loss: 0.6243, Val Loss: 0.6956\n",
      "Epoch [510/5000], Loss: 0.6233, Val Loss: 0.6947\n",
      "Epoch [520/5000], Loss: 0.6222, Val Loss: 0.6939\n",
      "Epoch [530/5000], Loss: 0.6210, Val Loss: 0.6939\n",
      "Epoch [540/5000], Loss: 0.6200, Val Loss: 0.6935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 578/5000 [00:02<00:18, 234.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [550/5000], Loss: 0.6188, Val Loss: 0.6948\n",
      "Epoch [560/5000], Loss: 0.6177, Val Loss: 0.6953\n",
      "Epoch [570/5000], Loss: 0.6164, Val Loss: 0.6965\n",
      "Epoch [580/5000], Loss: 0.6150, Val Loss: 0.6984\n",
      "Epoch [590/5000], Loss: 0.6139, Val Loss: 0.7008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 632/5000 [00:02<00:17, 245.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [600/5000], Loss: 0.6129, Val Loss: 0.7036\n",
      "Epoch [610/5000], Loss: 0.6121, Val Loss: 0.7033\n",
      "Epoch [620/5000], Loss: 0.6114, Val Loss: 0.7047\n",
      "Epoch [630/5000], Loss: 0.6107, Val Loss: 0.7051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Trenowanie modelu dla Vancouver\n",
    "city = 'Vancouver'\n",
    "model = WeatherModel(\n",
    "    input_size=train[city]['X'].shape[1],\n",
    "    hidden_sizes=(),\n",
    "    output_size_temp=1,\n",
    "    output_size_wind=1\n",
    ").to(device)\n",
    "\n",
    "# Definicja funkcji strat\n",
    "criterion_temp = nn.MSELoss()\n",
    "criterion_wind = nn.BCELoss()\n",
    "\n",
    "# Definicja optymalizatora\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Trenowanie modelu\n",
    "history = train_model(\n",
    "    model,\n",
    "    train[city],\n",
    "    val[city],\n",
    "    criterion_temp,\n",
    "    criterion_wind,\n",
    "    optimizer,\n",
    "    num_epochs=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Uzyskanie zestawu testowego\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_test_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m y_temp_test_tensor \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_temp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m y_wind_test_tensor \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_wind\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'X'"
     ]
    }
   ],
   "source": [
    "# Uzyskanie zestawu testowego\n",
    "X_test_tensor = test['X']\n",
    "y_temp_test_tensor = test['y_temp']\n",
    "y_wind_test_tensor = test['y_wind']\n",
    "\n",
    "# Przełącz model w tryb ewaluacji\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs_temp_test, outputs_wind_test = model(X_test_tensor)\n",
    "\n",
    "# Konwersja na NumPy\n",
    "y_temp_test_np = y_temp_test_tensor.numpy()\n",
    "outputs_temp_test_np = outputs_temp_test.squeeze().numpy()\n",
    "\n",
    "y_wind_test_np = y_wind_test_tensor.numpy()\n",
    "outputs_wind_test_np = outputs_wind_test.squeeze().numpy()\n",
    "\n",
    "# Predykcje klasyfikacyjne (próg 0.5)\n",
    "y_wind_pred_np = (outputs_wind_test_np >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
